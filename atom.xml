<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Crazy Cloud Ideas</title>
  
  
  <link href="/blog/atom.xml" rel="self"/>
  
  <link href="https://sameeraman.github.io/"/>
  <updated>2025-06-02T14:18:02.380Z</updated>
  <id>https://sameeraman.github.io/</id>
  
  <author>
    <name>Sameera Perera</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Building a Natural Language Interface for Home Assistant Using Semantic Kernel and Azure OpenAI</title>
    <link href="https://sameeraman.github.io/2025/06/02/semantickernelha/"/>
    <id>https://sameeraman.github.io/2025/06/02/semantickernelha/</id>
    <published>2025-06-02T09:34:48.000Z</published>
    <updated>2025-06-02T14:18:02.380Z</updated>
    
    <content type="html"><![CDATA[<p>In this project, I developed a Python application that leverages Microsoft’s Semantic Kernel and Azure OpenAI to enable natural language interactions with Home Assistant. By integrating the Model Context Protocol (MCP), this solution allows users to control and query their smart home devices seamlessly.</p><a id="more"></a><p>The complete source code and detailed documentation are available in my GitHub repository: <a href="https://github.com/sameeraman/semantic-kernel-examples" target="_blank" rel="noopener">semantic-kernel-examples</a>.</p><h2 id="Overview-of-Semantic-Kernel"><a href="#Overview-of-Semantic-Kernel" class="headerlink" title="Overview of Semantic Kernel"></a>Overview of Semantic Kernel</h2><p>Semantic Kernel is an open-source SDK developed by Microsoft that facilitates the integration of Large Language Models (LLMs) like Azure OpenAI into applications. It provides a framework to define plugins and functions that LLMs can invoke, enabling complex workflows and interactions through natural language prompts.</p><p>Key features include:</p><ul><li>Plugin Architecture: Encapsulate functionalities that can be invoked by LLMs.</li><li>Function Calling: Allow LLMs to execute predefined functions based on user prompts.</li><li>Memory Management: Maintain context over interactions for coherent conversations.</li><li>Planner: Orchestrate multi-step tasks by decomposing user intents into actionable steps.</li></ul><p>For more information, refer to the <a href="https://learn.microsoft.com/en-us/semantic-kernel/overview/" target="_blank" rel="noopener">Semantic Kernel documentation</a></p><h2 id="Architecture-Diagram-for-the-Project"><a href="#Architecture-Diagram-for-the-Project" class="headerlink" title="Architecture Diagram for the Project"></a>Architecture Diagram for the Project</h2><p><img src="Semantic-Kernel-ha-mcp.png" alt="Architecture Diagram"></p><p>The architecture diagram above illustrates the integration between Semantic Kernel and Home Assistant using the Model Context Protocol (MCP). Home Assistant exposes its MCP Server using Server-Sent Events (SSE) protocol, while Semantic Kernel’s MCP implementation supports Standard I/O (stdio). To bridge this gap, an MCP proxy is used to translate between these protocols. This proxy enables seamless communication between Semantic Kernel’s natural language processing capabilities and Home Assistant’s device control functionality, without requiring modifications to either platform.</p><h3 id="How-It-Works"><a href="#How-It-Works" class="headerlink" title="How It Works"></a>How It Works</h3><p>The agent uses:</p><ul><li><strong>Semantic Kernel</strong>: To build a smart agent with plugin/function calling capabilities</li><li><strong>Azure OpenAI</strong>: For natural language understanding and generation</li><li><strong>MCP Plugin</strong>: To integrate with Home Assistant API</li><li><strong>Bidirectional Communication</strong>: For real-time interactions with your smart home</li></ul><p>When a user inputs a command like <strong><em>“Turn on the office light”</em></strong>, the Semantic Kernel application begins processing the request. The natural language input is sent to Semantic Kernel, which uses Azure OpenAI to interpret the intent and understand the user’s request. If the intent is a home device control or status check, the Semantic Kernel utilizes a custom plugin called <code>MCPStdioPlugin</code>. This plugin serves as a bridge to Home Assistant by invoking a background process (mcp-proxy) that communicates over the SSE (Server-Sent Events) protocol. Based on the interpreted intent, the plugin selects the appropriate function, constructs a structured message and passes it to Home Assistant via the proxy. Home Assistant receives the message, carries out the corresponding action—like turning on the light—and returns a response. The Semantic Kernel application then displays a confirmation message back to the user, completing a seamless natural language interaction with the smart home.</p><h3 id="Setup-Requirements"><a href="#Setup-Requirements" class="headerlink" title="Setup Requirements"></a>Setup Requirements</h3><p>You can setup this if you have home assistant at home. You will need the following: </p><ol><li>An Azure OpenAI resource</li><li>Home Assistant server running the MCP integration (MCP Server can be installed as an add-on)</li><li>Python environment to run the Semantic Kernal Python Application.</li></ol><h3 id="Home-Assistant-Configuration"><a href="#Home-Assistant-Configuration" class="headerlink" title="Home Assistant Configuration"></a>Home Assistant Configuration</h3><p>To properly set up the integration with your Home Assistant instance:</p><ol><li><p><strong>Enable MCP Server Integration</strong>: </p><ul><li>Follow the official documentation at <a href="https://www.home-assistant.io/integrations/mcp_server/" target="_blank" rel="noopener">https://www.home-assistant.io/integrations/mcp_server/</a> to enable the MCP Server integration in your Home Assistant instance.</li><li>The MCP Server generates a secure URL endpoint that the Semantic Kernel agent will connect to.</li></ul></li><li><p><strong>Select Devices for Assistants</strong>: </p><ul><li>In your Home Assistant UI, navigate to Settings → Assistants</li><li>Select the devices you want to expose to the MCP Server integration</li><li>Only selected devices will be accessible through the Semantic Kernel agent</li></ul></li><li><p><strong>Generate Long-Lived Access Token</strong>:</p><ul><li>In your Home Assistant UI, go to your profile (click on your username in the bottom left)</li><li>Scroll down to “Long-Lived Access Tokens” section</li><li>Click “Create Token”, provide a name (e.g., “Semantic Kernel Agent”)</li><li>Copy the generated token immediately (it will only be shown once)</li><li>Add this token to your <code>.env</code> file as <code>HA_API_ACCESS_TOKEN=your_token_here</code></li></ul><p><strong>Example <code>.env</code> file:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">AZURE_OPENAI_DEPLOYMENT_NAME&#x3D;gpt-35-turbo</span><br><span class="line">AZURE_OPENAI_ENDPOINT&#x3D;https:&#x2F;&#x2F;&lt;open api instance&gt;.openai.azure.com&#x2F;</span><br><span class="line">AZURE_OPENAI_API_KEY&#x3D;&lt;Open API Key&gt;</span><br><span class="line">AZURE_OPENAI_CHAT_DEPLOYMENT_NAME&#x3D;gpt-35-turbo</span><br><span class="line">OPENAI_CHAT_MODEL_ID&#x3D;gpt-35-turbo</span><br><span class="line"></span><br><span class="line">HA_API_ACCESS_TOKEN&#x3D;&lt;Home Assistant Long Lived Token&gt;</span><br></pre></td></tr></table></figure></li><li><p><strong>Network Configuration</strong>: </p><ul><li>Ensure your Semantic Kernel agent can reach the Home Assistant MCP endpoint</li><li>Update the <code>SSE_URL</code> in the <code>se_agent_homeassistant.py</code> file to match your Home Assistant instance URL</li><li>Set the proper <code>HA_API_ACCESS_TOKEN</code> in your environment variables or <code>.env</code> file</li></ul></li><li><p><strong>Test Connectivity</strong>:</p><ul><li>Before running the agent, verify that your Home Assistant instance is accessible from the environment where you’re running the agent</li></ul></li></ol><h3 id="Running-the-Agent"><a href="#Running-the-Agent" class="headerlink" title="Running the Agent"></a>Running the Agent</h3><p>To run the agent, use the following command:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python se_agent_homeassistant.py</span><br></pre></td></tr></table></figure><p>Then start interacting with your Home Assistant through natural language!</p><h3 id="Example-Interactions"><a href="#Example-Interactions" class="headerlink" title="Example Interactions"></a>Example Interactions</h3><p>Here are some examples of how you can interact with your smart home through this agent:</p><p><strong>Querying Device Status:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">User &gt; What&#39;s the status of the office light?</span><br><span class="line">Assistant &gt; The status of the office light is currently &#39;on&#39; with a brightness level of 255</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">User &gt; What&#39;s the temperature in the living room?</span><br><span class="line">Assistant &gt; The temperature in the living room is 28.5°C.</span><br></pre></td></tr></table></figure><p><strong>Controlling Devices:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">User &gt; Turn off the that light please</span><br><span class="line">Assistant &gt; The office light has been turned off.</span><br></pre></td></tr></table></figure><p><strong>Complex Queries:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">User &gt; Which lights are currently on in the house?</span><br><span class="line">Assistant &gt; The following lights are currently on in the house:</span><br><span class="line">1. Living Light with a brightness level of 255</span><br><span class="line">2. Master Pendant Light with a brightness level of 98</span><br><span class="line">3. Living Mood Lights with a brightness level of 172</span><br><span class="line">4. Kitchen Strip with a brightness level of 133</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;In this project, I developed a Python application that leverages Microsoft’s Semantic Kernel and Azure OpenAI to enable natural language interactions with Home Assistant. By integrating the Model Context Protocol (MCP), this solution allows users to control and query their smart home devices seamlessly.&lt;/p&gt;
    
    </summary>
    
    
      <category term="AI" scheme="https://sameeraman.github.io/categories/ai/"/>
    
    
      <category term="Azure Open AI" scheme="https://sameeraman.github.io/tags/azure-open-ai/"/>
    
      <category term="AI" scheme="https://sameeraman.github.io/tags/ai/"/>
    
      <category term="LLM" scheme="https://sameeraman.github.io/tags/llm/"/>
    
      <category term="HomeAssistant" scheme="https://sameeraman.github.io/tags/homeassistant/"/>
    
  </entry>
  
  <entry>
    <title>Azure Arc Resource Bridge - End User Experience</title>
    <link href="https://sameeraman.github.io/2023/01/03/arcresourcebridge/"/>
    <id>https://sameeraman.github.io/2023/01/03/arcresourcebridge/</id>
    <published>2023-01-03T11:24:44.000Z</published>
    <updated>2025-06-02T14:18:02.363Z</updated>
    
    <content type="html"><![CDATA[<p>In this blog post, we will be looking at this new cool feature called Azure Arc Resource Bridge. </p><p>I have been deploying an Azure Stack HCI at home and I wanted to explore the Azure Arc Resource Bridge to lay some icing on the cake. This blog explains the end user experience, so that you will get an understanding what can be achieved using this service.  </p><a id="more"></a><p>Azure Arc Resource Bridge is a component of the Azure Arc Platform that provides self-serving capabilities for virtualized environments such as Azure Stack HCI and VMware. With that, you will be able to create, update and delete virtual machines in Azure Stack HCI clusters and VMware Clusters. All those environments can be centrally managed via the Azure Portal for their day-to-day operations. More importantly, you can use the same Infrastructure as Code tool sets to deploy and manage your workloads, regardless of where they are located. </p><h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><p>The high-level architecture for the Azure Arc Resource Bridge is shown below. </p><p><img src="architecture.png" alt="Architecture"></p><p>This includes two main components on the Azure side, cluster-extensions and custom locations. Custom location represents a logical location for the connected Azure Arc Resource Bridge. Cluster extension represents the projected components that is provisioned on-prem in the cluster. Note that Vmware and Stack HCI have different cluster extension components. </p><p>Once you have a setup Azure Arc Resource Bridge along side of your HCI cluster, you will see all the resources are projected into the Azure subscription. </p><p><img src="resources1.png" alt="Azure Resource Bridge Resources"></p><p>The above setup, there is a resource bridge resource that represents the resource bridge properties and configuration. Then we have a custom location resource that represents a location for the HCI. We also have Gallery Images that presents my windows image, then also have a vnet that represents my lab network at home. They are all projected as Azure Resources to work as a harmony to provision the required workloads in my lab environment.</p><h2 id="End-User-Experience"><a href="#End-User-Experience" class="headerlink" title="End User Experience"></a>End User Experience</h2><p>Let’s have a look at the end user experience of managing the VM’s when Azure Arc Resource Bridge is fully setup. </p><h3 id="Create-a-VM-using-the-Portal"><a href="#Create-a-VM-using-the-Portal" class="headerlink" title="Create a VM using the Portal"></a>Create a VM using the Portal</h3><p>Login to the Azure Portal and navigate to Virtual Machines.</p><p><img src="portal1.png" alt="Portal Experience Screenshot 1"></p><p><img src="portal2.png" alt="Portal Experience Screenshot 2"></p><p><img src="portal3.png" alt="Portal Experience Screenshot 3"><br>Select Resource Groups, enter VM Name, select, custom location and image reference. </p><p><img src="portal4.png" alt="Portal Experience Screenshot 4"><br>Enter Administrator username and Password. </p><p><img src="portal5.png" alt="Portal Experience Screenshot 5"><br>Add any additional data disks that is required for the VM. In my case, I’m not going to attach any additional data disks outside of the OS disk. </p><p><img src="portal6.png" alt="Portal Experience Screenshot 6"><br>Add the Network Adapters required under the networking blade.<br>I’ll be adding one Network interfaces connecting the VM to my lab network. </p><p><img src="portal7.png" alt="Portal Experience Screenshot 7"><br>I set the IP address to dynamic so it will get an IP address from the DHCP. </p><p><img src="portal8.png" alt="Portal Experience Screenshot 8"></p><p>Add any tags required. </p><p><img src="portal9.png" alt="Portal Experience Screenshot 9"><br>In Summary, Review and create. </p><p><img src="portal10.png" alt="Portal Experience Screenshot 10"></p><p><img src="portal11.png" alt="Portal Experience Screenshot 11"></p><p>Once the VM is successfully provisioned, you will see the VM in the resource group with the following properties.<br><img src="portal12.png" alt="Portal Experience Screenshot 12"></p><p>If I navigate to the Windows Admin Center, I can see the new VM has been created in the local cluster.<br><img src="portal13.png" alt="Portal Experience Screenshot 13"></p><p>The IP address on the VM is taken out from the local VNET that we created.<br><img src="portal14.png" alt="Portal Experience Screenshot 14"></p><p>The IP address that appears on the Azure VM in the portal is a IP address from the local VNET that we created.<br><img src="portal15.png" alt="Portal Experience Screenshot 15"></p><p>To double confirm, we will RDP into the VM and check the IP address of the newly created VM. It is the same VM.<br><img src="portal16.png" alt="Portal Experience Screenshot 16"></p><p>In summary, Azure Arc Resource Bridge is a service that allows users to manage virtual machines in Azure Stack HCI and VMware clusters through the Azure Portal, using the same management tools as the cloud. The service projects resources, such as virtual network and gallery images, into an Azure subscription to enable the deployment of workloads in on-premises environments. In this post we walked through the real life experience of management of VM’s in your local data center using the Azure Management pane. Hope this post was informative for you. </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;In this blog post, we will be looking at this new cool feature called Azure Arc Resource Bridge. &lt;/p&gt;
&lt;p&gt;I have been deploying an Azure Stack HCI at home and I wanted to explore the Azure Arc Resource Bridge to lay some icing on the cake. This blog explains the end user experience, so that you will get an understanding what can be achieved using this service.  &lt;/p&gt;
    
    </summary>
    
    
      <category term="Hybrid" scheme="https://sameeraman.github.io/categories/hybrid/"/>
    
    
      <category term="Hybrid" scheme="https://sameeraman.github.io/tags/hybrid/"/>
    
      <category term="Azure Arc" scheme="https://sameeraman.github.io/tags/azure-arc/"/>
    
      <category term="Resource Bridge" scheme="https://sameeraman.github.io/tags/resource-bridge/"/>
    
  </entry>
  
  <entry>
    <title>Classic VM Retirement - Am I safe ?</title>
    <link href="https://sameeraman.github.io/2022/10/01/classicvms/"/>
    <id>https://sameeraman.github.io/2022/10/01/classicvms/</id>
    <published>2022-10-01T11:24:44.000Z</published>
    <updated>2025-06-02T14:18:02.372Z</updated>
    
    <content type="html"><![CDATA[<p>Microsoft announced the retirement of the classic VMs in 2020. It’s been more than two years since then and the retirement date is fast approaching. 1st of March 2023, all classic VM’s that are not migrated to ARM will be stopped and deallocated according to the announcement.  This will cause disruptions to your workloads if you have an application in ASM that you are not across of.  To be honest, I found a few customers who is still running classic VMs mainly without awareness that they still have classic VMs in their environment. This blog post talks about a quick and easy way to find out if you have any classic VM’s in your environment that you don’t know of. </p><a id="more"></a><p>You will require access to the Azure Billing data in the last month. If you get an export of the billing data, load it it excel, and look for entries that contains “Microsoft.ClassicCompute” in the resourceId column, you should be able to find out if there are any classic VMs. See the example below that shows some example outputs.  </p><p><img src="image1.png" alt="Example"></p><p>If you find any entries, you can then evaluate if those are still required, then plan for ARM migration appropriately.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Microsoft announced the retirement of the classic VMs in 2020. It’s been more than two years since then and the retirement date is fast approaching. 1st of March 2023, all classic VM’s that are not migrated to ARM will be stopped and deallocated according to the announcement.  This will cause disruptions to your workloads if you have an application in ASM that you are not across of.  To be honest, I found a few customers who is still running classic VMs mainly without awareness that they still have classic VMs in their environment. This blog post talks about a quick and easy way to find out if you have any classic VM’s in your environment that you don’t know of. &lt;/p&gt;
    
    </summary>
    
    
      <category term="Compute" scheme="https://sameeraman.github.io/categories/compute/"/>
    
    
      <category term="Compute" scheme="https://sameeraman.github.io/tags/compute/"/>
    
      <category term="Virtual Machines" scheme="https://sameeraman.github.io/tags/virtual-machines/"/>
    
  </entry>
  
  <entry>
    <title>Azure Site Recovery Plan Example Explained</title>
    <link href="https://sameeraman.github.io/2022/01/29/azuresiterecoveryplan/"/>
    <id>https://sameeraman.github.io/2022/01/29/azuresiterecoveryplan/</id>
    <published>2022-01-29T11:00:00.000Z</published>
    <updated>2025-06-02T14:18:02.370Z</updated>
    
    <content type="html"><![CDATA[<p>Recently I was working on a demo for a customer on Azure Site Recovery Plans and I thought I share my setup in here so that it would be beneficial for someone else as well. This post includes an end-to-end demo of Azure Site Recovery Plans along with a real world sample application. </p><a id="more"></a><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>In summary, I have an environment that has two virtual networks, one in West US 2 and one in East US. Both of the networks are connected to the on-premises via a central hub network. I have a two tier application that runs in the West US 2 region. The sample application is a Todo Application that has a DotNet core 6 web application and a SQL backend (<a href="https://github.com/sameeraman/DotNetCoreSQLDB" target="_blank" rel="noopener">https://github.com/sameeraman/DotNetCoreSQLDB</a>).  So the overall setup looks as below. </p><p><img src="asrlabsetup.png" alt="asrlabsetup.png"></p><h3 id="Experience"><a href="#Experience" class="headerlink" title="Experience"></a>Experience</h3><p>When you access the application in the Primary (West US 2) region, you will see the application as below. </p><p><img src="todoapp.png" alt="todoapp.png"></p><p>I have enabled ASR replication on the the application server and the SQL Server. Then <a href="http://docs.microsoft.com/en-us/azure/site-recovery/site-recovery-create-recovery-plans" target="_blank" rel="noopener">Create a Recovery plan</a> under the Azure Site recovery.  This process is straight forward. </p><blockquote><p>In Production environments, you would normally have SQL HA/DR setup for the database to failover. Eg. You would configure SQL Always-On Replication between the two regions. You can have a asynchronously replicating database on the East US region. Then you will failover the database on the SQL Level rather than the VM level that is used in this sample.</p></blockquote><p>I want to show you how to tune the failover sequence and also to customize the failover with custom script activities. </p><p>You can add custom scripts via Azure automation account runbooks to the ASR Recovery plans. This make it possible to literally do anything you want as part of your recovery plan. Some of the common uses of the custom scripts are below: </p><ul><li>Add a VM Behind a load balancer after the failover</li><li>Create a Public IP for the failed over VM.</li><li>Update NSG rules with Failed over VM IP addresses.</li><li>Failover SQL Always on Availability Group to the DR with the Servers.</li><li>Update DNS records post failover</li></ul><p>In the above example, I’ll be using a custom script to update the SQL connection string, SQL Server IP address with the new IP address. I use the <code>Invoke-AzVMRunCommand</code> <a href="https://docs.microsoft.com/en-us/powershell/module/az.compute/invoke-azvmruncommand?WT.mc_id=itopstalk-blog-thmaure&view=azps-7.1.0" target="_blank" rel="noopener">Powershell command</a> to run a script on the server to update the connection string.</p><p>Have a look at the Runbook PowerShell script here - <a href="https://github.com/sameeraman/Scripts/blob/master/ASRRunbookSample/UpdateSQLIP.ps1" target="_blank" rel="noopener">UpdateSQLIP.ps1</a></p><p>I also have another script that add a 1 minute delay for the failover between the two servers. It’s actually not required, but I have added it to showcase another use of scripts. That script can be found in the link here - <a href="https://github.com/sameeraman/Scripts/blob/master/ASRRunbookSample/Delay1minute.ps1" target="_blank" rel="noopener">Delay1minute.ps1</a>.</p><p>So putting them all together in the Recovery plan, it looks as below. </p><p><img src="rplan1.png" alt="rplan1.png"></p><p><img src="rplan2.png" alt="rplan2.png"></p><p>The Runbooks in the automation Account looks as below: </p><p><img src="runbooks.png" alt="runbooks.png"></p><p>When you failover using this Recovery Plan, you will see the application comes up successfully on the East US region and the application accessible using the new IP. You will see the Connection string has been updated with the new IP address after the failover. </p><p><img src="failover1.png" alt="failover1.png"></p><p><img src="failover2.png" alt="failover2.png"></p><p><img src="failover3.png" alt="failover3.png"></p><p>As you can see the application has been successfully failed over to the secondary region. The orchestration was fully automated end-to-end. </p><p>Using the same recovery plan, you can also fail back to the primary region again. But I will not cover that in this blog. </p><h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>As you can see, Azure Site Recovery Plans let’s you <strong>fully automate the application infrastructure failover</strong> and <strong>reduce the RTO</strong> in your application. It allows you to add <strong>pre and post actions</strong> for each group you failover. <strong>Azure Automation Runbook scripts</strong> make it possible to execute <strong>anything you like as pre and post tasks</strong>.</p><p>I made full video with an end-to-end demo on the above. Click on the link below to watch the video.<br><a href="https://www.youtube.com/watch?v=vF6d2GhL5wo" target="_blank" rel="noopener"><img src="https://img.youtube.com/vi/vF6d2GhL5wo/0.jpg" alt="Site Recovery Plans Youtube Video"></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Recently I was working on a demo for a customer on Azure Site Recovery Plans and I thought I share my setup in here so that it would be beneficial for someone else as well. This post includes an end-to-end demo of Azure Site Recovery Plans along with a real world sample application. &lt;/p&gt;
    
    </summary>
    
    
      <category term="ASR" scheme="https://sameeraman.github.io/categories/asr/"/>
    
    
      <category term="ASR" scheme="https://sameeraman.github.io/tags/asr/"/>
    
      <category term="Site Recovery" scheme="https://sameeraman.github.io/tags/site-recovery/"/>
    
  </entry>
  
  <entry>
    <title>AKS Persistent Storage – Azure Files Dynamic Provisioning</title>
    <link href="https://sameeraman.github.io/2021/11/07/aksstorageazfilesdynamic/"/>
    <id>https://sameeraman.github.io/2021/11/07/aksstorageazfilesdynamic/</id>
    <published>2021-11-07T11:00:00.000Z</published>
    <updated>2025-06-02T14:18:02.361Z</updated>
    
    <content type="html"><![CDATA[<p>As you create and manage AKS clusters, you will soon enough understand that your application needs persistent storage to store application data. There are many different options available in AKS with Azure Native services. In this blog post we will be closing looking at using azure files as the persistent storage with the dynamic provisioning capabilities. </p><a id="more"></a><p>When you create a AKS cluster you will notice that you get a few storage classes already added to it. </p><p><img src="image1.png" alt="Default Storage Classes"></p><p>Azure files premium and azure files standard storage classes comes by default in the AKS clusters. You can leverage these storage classes to dynamically create persistent storage for your application. Let’s look at an example and see how the AKS cluster behaves at the backend. </p><p>The commands and the deployment information are in this <a href="https://github.com/sameeraman/aks-storage/tree/main/azurefiles" target="_blank" rel="noopener">github repo</a>. </p><p>I assume that you have got a Kubernetes cluster already running. We will be creating a PVC with Azure files premium and a deployment with nginx to use it. </p><p>First use the <code>dynamic_provisioning.yaml</code> file to create the pvc and the deployment. </p><p><img src="image2.png" alt="PVC and Deployment"></p><p>Then remote into the pod that is running. Navigate to the mapped share and create a file as below.</p><p><img src="image3.png" alt="Create new file"></p><p>Scale the deployment to 5 instances as below. </p><p><img src="image4.png" alt="Scale the instance to 5"></p><p>Once all the pods are running, remote into a different pod and run the following commands. </p><p><img src="image5.png" alt="Scale the instance to 5"></p><p>Then go to the Azure Portal, browse to the azure files storage account, and check the content. </p><p><img src="image6.png" alt="Scale the instance to 5"></p><p><img src="image7.png" alt="Scale the instance to 5"></p><p><img src="image8.png" alt="Scale the instance to 5"></p><p><img src="image9.png" alt="Scale the instance to 5"></p><p>As you can see, the storage is available across multiple pods, and the pods are able to read write to the storage at the same time.  The storage content is also available via the Azure Portal. </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;As you create and manage AKS clusters, you will soon enough understand that your application needs persistent storage to store application data. There are many different options available in AKS with Azure Native services. In this blog post we will be closing looking at using azure files as the persistent storage with the dynamic provisioning capabilities. &lt;/p&gt;
    
    </summary>
    
    
      <category term="AKS" scheme="https://sameeraman.github.io/categories/aks/"/>
    
    
      <category term="AKS" scheme="https://sameeraman.github.io/tags/aks/"/>
    
      <category term="Kuberenetes" scheme="https://sameeraman.github.io/tags/kuberenetes/"/>
    
      <category term="Storage" scheme="https://sameeraman.github.io/tags/storage/"/>
    
      <category term="Files" scheme="https://sameeraman.github.io/tags/files/"/>
    
  </entry>
  
  <entry>
    <title>Server to Server Data copy using AzCopy</title>
    <link href="https://sameeraman.github.io/2021/09/14/azcopydatatransfer/"/>
    <id>https://sameeraman.github.io/2021/09/14/azcopydatatransfer/</id>
    <published>2021-09-14T11:00:00.000Z</published>
    <updated>2025-06-02T14:18:02.369Z</updated>
    
    <content type="html"><![CDATA[<p>If you are migrating your workloads to the cloud, you most probably have come across in scenarios where you need to copy large amount of data cross the network into the cloud. In this post, I’m going to be talking about my experience in one of those scenarios and my observations. The observations and learning are interesting and worth sharing. Therefore, continue reading this article to the end. </p><a id="more"></a><h2 id="Problem-Statement"><a href="#Problem-Statement" class="headerlink" title="Problem Statement"></a>Problem Statement</h2><p>Recently, I was involved in a Server-to-Server data migration over the Azure ExpressRoute. This scenario had a high latency connection from the on-promises to the cloud; it was around 60ms route trip time.  </p><p><img src="robocopy_arch.png" alt="Robocopy Architecture"></p><p>I initially used Robocopy tool to migrate the files and wasn’t experiencing a great bandwidth consumption during the migration. I was able to achieve maximum 280Mbps even though I used multithread data copy using the robocopy option. I had plenty of capacity available in the ExpressRoute, however, robocopy was not pushing the data transfer speeds beyond this limit.<br>Following is an example small copy result. </p><p><img src="robocopy.png" alt="Robocopy Architecture"></p><p>As you can see, it was only achieving <code>265Mbps</code>. </p><h2 id="Investigation"><a href="#Investigation" class="headerlink" title="Investigation"></a>Investigation</h2><p>While reading about the Robocopy, I learned, even if we use multi-threaded flag, with high latency data copy it doesn’t achieve a high speed because it uses SMB for the data transfer. In other words, Robocopy is not the best tool to copy data across high latency connections. The reason for that is SMB protocol is not designed to copy with high latency connections. There is a single TCP connection maximum bandwidth limit to be aware here has well. In Azure, there are some measured single session TCP maximum bandwidth limits documented <a href="https://docs.microsoft.com/en-us/azure/expressroute/expressroute-troubleshooting-network-performance#latencybandwidth-results" target="_blank" rel="noopener">here</a>. This will give you a guide around the limits. </p><p>Moving on from Robocopy, I used FTP as another method for the copy job. I used <a href="https://filezilla-project.org/" target="_blank" rel="noopener">FileZilla</a> tool for this. This required an FTP server to be configured on the source side; and the data to be pulled from an FTP client at the target side. Note that this also required additional ports (port 21 by default) opened between the source server and the destination.<br>I managed to achieve slightly higher data transfer rates using this method, however, still it wasn’t utilizing the full ExpressRoute bandwidth. This resulted in me looking for other options. </p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><p>I initially looked at using <a href="https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10" target="_blank" rel="noopener">azcopy</a> tool for this job. However, I didn’t go with this path because it can only copy files to an Azure Storage account, e.g. Blob store. Because of the low maximum bandwidth achieved from the robocopy and FTP, I was compelled to investigate this method again. My requirement was to copy files from the source server to the destination server, therefore with azcopy, I had to (1) first upload the files to a staging storage account, then (2) download the files the destination server. Even though this is a two-step approach, this gave me faster throughputs during the copy. This resulted in a significantly quicker end to end completion time compared to the robocopy. The key point to mention here is, azcopy is designed for high latency copy jobs. Therefore, it pushes the throughputs to the maximum available in the link. </p><p><img src="azcopy_arch.png" alt="AzCopy Architecture"></p><p>With the usage of the Azure Private endpoints, the route of the file transfer traffic, still stays the same. It copies the files over the ExpressRoute to the same virtual network. Therefore, from a security perspective, it’s not a huge compromise. </p><p>What is significant to note in here is the download speed from the storage account to the target server. Because they are in the same region, it managed to achieve throughputs as high as 10Gbps. Therefore, time taken in the step 2 is neglectable when compared to the step 1.</p><p>Following is an example upload speed achieved. </p><p><img src="transfer_speed_1.png" alt="Upload Speed"></p><p>Following is an example download speed achieved. </p><p><img src="transfer_speed_2.png" alt="Download Speed"></p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>The conclusion here is, direct copy using traditional methods (like robocopy) in high latency scenarios, especially migrating data to the cloud, is not always the best method. There are other tools specifically designed for high latency scenarios (like azcopy). Even though they can’t do server-to-server direct copy, they can perform better in a two-step approach to migrate the files to the destination/cloud. </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;If you are migrating your workloads to the cloud, you most probably have come across in scenarios where you need to copy large amount of data cross the network into the cloud. In this post, I’m going to be talking about my experience in one of those scenarios and my observations. The observations and learning are interesting and worth sharing. Therefore, continue reading this article to the end. &lt;/p&gt;
    
    </summary>
    
    
      <category term="Networking" scheme="https://sameeraman.github.io/categories/networking/"/>
    
    
      <category term="Networking" scheme="https://sameeraman.github.io/tags/networking/"/>
    
      <category term="ExpressRoute" scheme="https://sameeraman.github.io/tags/expressroute/"/>
    
      <category term="PrivateLink" scheme="https://sameeraman.github.io/tags/privatelink/"/>
    
      <category term="AzCopy" scheme="https://sameeraman.github.io/tags/azcopy/"/>
    
  </entry>
  
  <entry>
    <title>Azure Management Groups Activity logs to Azure Monitor</title>
    <link href="https://sameeraman.github.io/2021/06/20/mgauditlogs/"/>
    <id>https://sameeraman.github.io/2021/06/20/mgauditlogs/</id>
    <published>2021-06-20T18:34:48.000Z</published>
    <updated>2025-06-02T14:18:02.376Z</updated>
    
    <content type="html"><![CDATA[<p>This blog post shows you how to forward your Azure Management Group Activity logs to Azure Monitor or any SIEM product that you have in your environment. There is a known limitation that this cannot be configured in the Azure Portal. It needs to be enabled using the backed API and this post will provide the necessary details for it. This is important for some Azure Customers as Management Groups defines the organizations top level governances, including Azure Policy and Access Management. </p><a id="more"></a><h2 id="Problem-Statement"><a href="#Problem-Statement" class="headerlink" title="Problem Statement"></a>Problem Statement</h2><p>As of today (20/06/2021), Azure Portal does not allow you to configure Diagnostic settings at the management group level. If you go to Diagnostic settings at the management groups, it takes you to a page where it asks again for a resource to configure diagnostic settings on – see below animation. </p><p><img src="2BgPrLKVe6.gif" alt="MG Diagnostic Issue Animation"></p><p>Not that you don’t get a place to configure diagnostic setting for management groups.  This is a known limitation. You can see the activity logs on the Azure Portal for Management groups if you go to the Activity Logs pane on a management group; however, you cannot forward them to Azure Monitor nor any SIEM project. This is a problem for some customers, as they want to use Azure Monitor to monitor the entire cloud landscape rather than browsing through different locations. Furthermore, some customers want to query a single log analytics workspace for platform level analytics. The only way to do that is to forward all the logs to the Azure Monitor. Without wasting anymore time, lets look how it can be done.</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><p>The good news is - there is a way that this can be achieved. The diagnostic settings at the management group level can only be enabled and configured via the APIs at this time.  The API is available in the following location. </p><p><a href="https://docs.microsoft.com/en-us/rest/api/monitor/managementgroupdiagnosticsettings/createorupdate" target="_blank" rel="noopener">https://docs.microsoft.com/en-us/rest/api/monitor/managementgroupdiagnosticsettings/createorupdate</a></p><p>With this API you can configure diagnostic settings on the management groups. Diagnostic settings allow you to configure forwarding rule for activity logs to 3 locations, consistent with any other resource type in Azure. They are as below.</p><ol><li>Log analytics workspace</li><li>Storage account</li><li>Event Hubs. </li></ol><p>Before you call this API, you will need to have a valid bearer token acquired through the Azure AD. If you are unfamiliar with the process on calling the Azure API’s. This <a href="https://docs.microsoft.com/en-us/rest/api/azure/" target="_blank" rel="noopener">API documentation</a> is a good place to start. There are certain pre-requisites items such as creating a service principal and assigning permissions that needs to occur, this is detailed in the documentation along with a youtube video.<br>I used <a href="https://www.postman.com/" target="_blank" rel="noopener">Postman</a> as the tool to call the above API. Following are some of the details of the API calls I made to set this diagnostic settings </p><h3 id="Get-the-Bearer-Token"><a href="#Get-the-Bearer-Token" class="headerlink" title="Get the Bearer Token"></a>Get the Bearer Token</h3><p>I used the following API to get the Bearer token from the Azure AD.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https:&#x2F;&#x2F;login.microsoftonline.com&#x2F;&lt;tenant id&gt;&#x2F;oauth2&#x2F;token</span><br></pre></td></tr></table></figure><p>The request and the response screenshot in Postman is below.<br><img src="bearer.png" alt="Bearer Token Screenshot"></p><h3 id="List-the-Existing-Diagnostic-Settings-on-a-Given-Management-Group"><a href="#List-the-Existing-Diagnostic-Settings-on-a-Given-Management-Group" class="headerlink" title="List the Existing Diagnostic Settings on a Given Management Group."></a>List the Existing Diagnostic Settings on a Given Management Group.</h3><p>I used the following API to list the existing diagnostic configuration on the management group. </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https:&#x2F;&#x2F;management.azure.com&#x2F;providers&#x2F;microsoft.management&#x2F;managementGroups&#x2F;wtt-ml-sandboxes&#x2F;providers&#x2F;microsoft.insights&#x2F;diagnosticSettings?api-version&#x3D;2020-01-01-preview</span><br></pre></td></tr></table></figure><p>The request and response of the GET call in Postman looks like below. </p><p><img src="get.png" alt="Get Request"></p><h3 id="Configure-a-Diagnostic-Setting-to-send-logs-to-a-Log-Analytics-workspace"><a href="#Configure-a-Diagnostic-Setting-to-send-logs-to-a-Log-Analytics-workspace" class="headerlink" title="Configure a Diagnostic Setting to send logs to a Log Analytics workspace."></a>Configure a Diagnostic Setting to send logs to a Log Analytics workspace.</h3><p>I used the following API to update the diagnostic configuration on the management group <code>wtt-ml-sandboxes</code>. </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https:&#x2F;&#x2F;management.azure.com&#x2F;providers&#x2F;microsoft.management&#x2F;managementGroups&#x2F;wtt-ml-sandboxes&#x2F;providers&#x2F;microsoft.insights&#x2F;diagnosticSettings&#x2F;testdiag?api-version&#x3D;2020-01-01-preview</span><br></pre></td></tr></table></figure><p>The request and response of the PUT call in Postman looks like below.<br><img src="put.png" alt="Put Request"></p><p>This is all you need to configure the diagnostic settings on the management group. The configuration takes 5-10 minutes for logs to appear in the log analytics workspace. If you go to the Log analytics workspace, you will see the data getting logged in the same <code>AzureActivity</code> Logs table. </p><p><img src="loga1.png" alt="Log Analytics Screenshot 1"></p><p>The log format is as below. </p><p><img src="loga2.png" alt="Log Analytics Screenshot 2"></p><p>You can use this table and the data in any Log Analytics query that you want to formulate. </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This blog post shows you how to forward your Azure Management Group Activity logs to Azure Monitor or any SIEM product that you have in your environment. There is a known limitation that this cannot be configured in the Azure Portal. It needs to be enabled using the backed API and this post will provide the necessary details for it. This is important for some Azure Customers as Management Groups defines the organizations top level governances, including Azure Policy and Access Management. &lt;/p&gt;
    
    </summary>
    
    
      <category term="Governance" scheme="https://sameeraman.github.io/categories/governance/"/>
    
    
      <category term="Governance" scheme="https://sameeraman.github.io/tags/governance/"/>
    
  </entry>
  
  <entry>
    <title>Azure Virtual WAN N region Bicep Template</title>
    <link href="https://sameeraman.github.io/2021/04/10/vwanntemplate/"/>
    <id>https://sameeraman.github.io/2021/04/10/vwanntemplate/</id>
    <published>2021-04-10T09:34:48.000Z</published>
    <updated>2025-06-02T14:18:02.385Z</updated>
    
    <content type="html"><![CDATA[<p>This blog post is about a Bicep Template that I authored to create a lab environment for customer scenarios and use cases. It creates a VWAN with N number of VWAN hubs in N regions. It also creates spoke VNet in each region including a VM. The template can be found in the following location with further details on how to use it.</p><a id="more"></a><p><a href="https://github.com/sameeraman/n_vwan_bicep_template" target="_blank" rel="noopener">https://github.com/sameeraman/n_vwan_bicep_template</a></p><p>Some of the example implementations that you can do using the template are below. </p><h2 id="Azure-VWAN-2-Region-Setup"><a href="#Azure-VWAN-2-Region-Setup" class="headerlink" title="Azure VWAN 2 Region Setup"></a>Azure VWAN 2 Region Setup</h2><p>You can provision an Azure VWAN 2 region model including 2 VWAN Hubs, a VNET and VM in each region. The final solution after deployment will look like below. </p><p><img src="vWAN2R_B.png" alt="VWAN 2 Region"></p><h2 id="Azure-VWAN-3-Region-Setup"><a href="#Azure-VWAN-3-Region-Setup" class="headerlink" title="Azure VWAN 3 Region Setup"></a>Azure VWAN 3 Region Setup</h2><p>You can also provision a setup with 3 VWAN hubs like above. The final solution after deployment will like below.</p><p><img src="vWAN3R_B.png" alt="VWAN 3 Region"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This blog post is about a Bicep Template that I authored to create a lab environment for customer scenarios and use cases. It creates a VWAN with N number of VWAN hubs in N regions. It also creates spoke VNet in each region including a VM. The template can be found in the following location with further details on how to use it.&lt;/p&gt;
    
    </summary>
    
    
      <category term="Networking" scheme="https://sameeraman.github.io/categories/networking/"/>
    
    
      <category term="Networking" scheme="https://sameeraman.github.io/tags/networking/"/>
    
      <category term="VWAN" scheme="https://sameeraman.github.io/tags/vwan/"/>
    
      <category term="Bicep" scheme="https://sameeraman.github.io/tags/bicep/"/>
    
  </entry>
  
  <entry>
    <title>Azure Global Reach in Action</title>
    <link href="https://sameeraman.github.io/2020/11/04/globalreach/"/>
    <id>https://sameeraman.github.io/2020/11/04/globalreach/</id>
    <published>2020-11-04T11:24:44.000Z</published>
    <updated>2025-06-02T14:18:02.374Z</updated>
    
    <content type="html"><![CDATA[<p>Recently, I was lucky to get two ExpressRoutes in a Microsoft Lab environment so that I could test the Azure Global Reach in Action. ExpressRoutes are not something you can test typically like the other resources in Azure, because it requires, customer router configuration, last mile provider configuration. Therefore, I thought I would share my experience with the rest of the world. This blog post is around the experience, a bit of a glimpse, to what happens when you enable Azure Global Reach. </p><a id="more"></a><p>A bit of background on the environment that I setup is below. I have two on-premises data centers, one in Seattle, one in Washington DC. They are connected to their local Azure regions respectively, in West US2 and East US. </p><p><img src="GlobalPeering1.png" alt="Lab Setup Diagram"></p><p>I have also cross connected the two ExpressRoute together so that one on-premises datacenter can talk to each other Azure datacenter using the ExpressRoute. This is allowed with a standard ExpressRoute between the same <a href="https://docs.microsoft.com/en-us/azure/expressroute/expressroute-locations-providers#locations" target="_blank" rel="noopener">geopolitical region</a>.  However, this setup doesn’t allow me to talk from one on-premises datacenter to the other on-premises datacenter. For this to happen I would need Azure Global Reach enabled. Let do some testing to verify this behavior. </p><p><img src="pingtest1.png" alt="Connectivity Test Before"></p><p>As you can see in the above ping tests, from a test machines in Washington DC, I can reach to East US and West US2 but not the Seattle on-premises VM.<br>My ExpressRoute Connections currently looks as below. </p><p><img src="ERConnections.png" alt="ExpressRoute Connections"></p><p>There are two connections on each ExpressRoute, One to each Azure Datacenter region.  </p><p>If I check my routes that appear in one of the ExpressRoutes, It will look like below. </p><p><img src="Routes1.png" alt="Route List Before"></p><p>Now let’s go ahead and enable Global Reach in my two ExpressRoutes. This is something you cannot do in the Azure Portal as of today. You must use PowerShell to enable Global Reach. The instructions to enable Global reach can be found in this <a href="https://docs.microsoft.com/en-us/azure/expressroute/expressroute-howto-set-global-reach" target="_blank" rel="noopener">article</a>. In my case I ran the following PowerShell Commands. It creates following orange connection. </p><p><img src="GlobalPeering2.png" alt="Lab Setup Diagram with Global Reach"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ER1RG &#x3D; &quot;Company17&quot;</span><br><span class="line">$ER1 &#x3D; &quot;Company17-er&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$ER2RG &#x3D; &quot;AComp17&quot;</span><br><span class="line">$ER2 &#x3D; &quot;AComp17-er&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$ckt_1 &#x3D; Get-AzExpressRouteCircuit -Name $ER1 -ResourceGroupName $ER1RG</span><br><span class="line">$ckt_2 &#x3D; Get-AzExpressRouteCircuit -Name $ER2 -ResourceGroupName $ER2RG</span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">$PeeringAddressPrefix1 &#x3D; &#39;10.200.0.0&#x2F;29&#39;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Add-AzExpressRouteCircuitConnectionConfig -Name &#39;GlobalReach-EastUS&#39; -ExpressRouteCircuit $ckt_1 -PeerExpressRouteCircuitPeering $ckt_2.Peerings[0].Id -AddressPrefix $PeeringAddressPrefix1</span><br><span class="line">Set-AzExpressRouteCircuit -ExpressRouteCircuit $ckt_1</span><br></pre></td></tr></table></figure><p>The Peering Address Prefix is a /29 ip range that does not overlap in your existing environment. Once the PowerShell commands are successfully executed, you will see this additional property on the ExpressRoute. It will appear only on the ExpressRoute that you execute the command. It will not appear on the other ExpressRoute. However, routing will work both ways. </p><p><img src="ERPeering.png" alt="ExpressRoute Peering Configuration"></p><p>If I go back and do my connectivity tests, I can see it is working as below. </p><p><img src="pingtest2.png" alt="Ping Test after"></p><p>If I look at the advertised routes in an ExpressRoute now, you will see the following. </p><p><img src="Routes2.png" alt="Route Listing after"></p><p>You will see three additional entries with the peering prefix IP address you provided. The first one is the path to the Washington DC Datacenter from the Seattle datacenter. Because of this path, it adds two more additional paths to the East US Azure DC and West US 2 DC. Those are added as well.<br>You will not see any changes on the ER connections in the portal. They remain the same. </p><p>This is how technically Global reach works. I add additional routes to your ExpressRoute which advertises the other data center IP ranges in your local ExpressRoute. </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Recently, I was lucky to get two ExpressRoutes in a Microsoft Lab environment so that I could test the Azure Global Reach in Action. ExpressRoutes are not something you can test typically like the other resources in Azure, because it requires, customer router configuration, last mile provider configuration. Therefore, I thought I would share my experience with the rest of the world. This blog post is around the experience, a bit of a glimpse, to what happens when you enable Azure Global Reach. &lt;/p&gt;
    
    </summary>
    
    
      <category term="Networking" scheme="https://sameeraman.github.io/categories/networking/"/>
    
    
      <category term="Networking" scheme="https://sameeraman.github.io/tags/networking/"/>
    
      <category term="ExpressRoute" scheme="https://sameeraman.github.io/tags/expressroute/"/>
    
      <category term="GlobalReach" scheme="https://sameeraman.github.io/tags/globalreach/"/>
    
  </entry>
  
  <entry>
    <title>Under the Hood of this Blog</title>
    <link href="https://sameeraman.github.io/2020/10/18/underthehood/"/>
    <id>https://sameeraman.github.io/2020/10/18/underthehood/</id>
    <published>2020-10-18T09:34:48.000Z</published>
    <updated>2025-06-02T14:18:02.380Z</updated>
    
    <content type="html"><![CDATA[<p>I recently decided to shift my gears with static pages for my blog. I have been using wordpress for all my blog publication so far. You can find my old blog <a href="https://sameeraman.wordpress.com/" target="_blank" rel="noopener">here</a>. With the trend of static pages, I thought of re-inventing the backend of my blog. And here we are, you are reading my new blog based on static pages which is hosted on Github pages. In this blog post, I am going to show you what happens under the hood when I publish a new article.</p><a id="more"></a><p>I was aware that the static pages had some limits around support for comments, analytics etc. But things have progressed a quiet a bit recently. There are smart ways to achieve these and tools available to make our life simple. Therefore, blogs are moving to static pages in the developer community these days. </p><p>The idea of the static pages-based blog is to keep the raw data of the blog some where and use a tool to generate the static pages for the blog. The raw data for the blog could be markdown files, JSON documents or any other meta data storing mechanism. There is plethora of tools available to convert the raw blog data to static pages.  <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> , <a href="https://www.gatsbyjs.com/" target="_blank" rel="noopener">Gatsby</a> and <a href="https://jekyllrb.com/" target="_blank" rel="noopener">Jekyllrb</a> are a few to name. Once you have generated the static pages, you can publish the static pages in a several hosting places. A few of them are <a href="https://pages.github.com/" target="_blank" rel="noopener">Github pages</a>, <a href="https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-static-website" target="_blank" rel="noopener">Azure Storage Web</a>, and <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteHosting.html" target="_blank" rel="noopener">AWS S3 bucket</a>.</p><p>As you can see there are plenty of options to choose from for each component. Each one of those, has its own strengths and weaknesses.  If you are thinking of using static pages for your blog, best is to try a few of those and find the one that works for you. </p><p>Now, let me explain you how this blog works. In very high-level, the following diagram depicts the process and what happens under the hood when I publish a new post. </p><p><img src="blogdiagram1.png" alt="Blog Under the Hood Diagram"></p><p>Firstly, I use <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> as the static page generator. Hexo has specialized features for hosting blogs and it supports Markdown files as source. This tool simplified my comment system, analytics and RSS feeds etc. Then I built others around it. I use a Github private repo for storing my source blog metadata. I edit and author locally, then push and merge the changes to private Github repo. Then I have configured a Github action to trigger when there is a new commit to the blog source repo. It will use a build agent, install Hexo, NodeJS and other necessary dependencies, build the static pages and push them to the public blog repo. The public blog repo is configured with Github pages. Once the static pages are published, the pages will be available through the Github pages to the public internet. A new post release process is fully automated using Github actions as you can see. That is the under the hood story which generated this page you are reading today.  </p><p>There are themes available for Hexo which can be used to change the look and feel. I have used <a href="https://github.com/cofess/hexo-theme-pure" target="_blank" rel="noopener">pure theme</a> and customized it according how I want to look it like. </p><p>I hope this post is informative for you. Hope this will convince you to start or migrate your blog over to static pages. </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I recently decided to shift my gears with static pages for my blog. I have been using wordpress for all my blog publication so far. You can find my old blog &lt;a href=&quot;https://sameeraman.wordpress.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;here&lt;/a&gt;. With the trend of static pages, I thought of re-inventing the backend of my blog. And here we are, you are reading my new blog based on static pages which is hosted on Github pages. In this blog post, I am going to show you what happens under the hood when I publish a new article.&lt;/p&gt;
    
    </summary>
    
    
      <category term="DevOps" scheme="https://sameeraman.github.io/categories/devops/"/>
    
    
      <category term="Static Pages" scheme="https://sameeraman.github.io/tags/static-pages/"/>
    
      <category term="Github" scheme="https://sameeraman.github.io/tags/github/"/>
    
      <category term="DevOps" scheme="https://sameeraman.github.io/tags/devops/"/>
    
      <category term="Hexo" scheme="https://sameeraman.github.io/tags/hexo/"/>
    
      <category term="Github Actions" scheme="https://sameeraman.github.io/tags/github-actions/"/>
    
  </entry>
  
  <entry>
    <title>Connect Ubiquiti USG to Azure VWAN Gateway using BGP</title>
    <link href="https://sameeraman.github.io/2020/10/05/usg2vwanbgp/"/>
    <id>https://sameeraman.github.io/2020/10/05/usg2vwanbgp/</id>
    <published>2020-10-05T09:34:48.000Z</published>
    <updated>2025-06-02T14:18:02.381Z</updated>
    
    <content type="html"><![CDATA[<p>In this blog post, I’m going to be sharing my knowledge that I gathered during a lab setup. Last weekend, I was playing with Ubiquiti USG BGP features and was wondering If I could establish BGP peering with my Azure VPN Gateway. This way, it could dynamically exchange routes between my home network and Azure. I typically have a hybrid networking configured between my home network and Azure. My Azure network is very dynamic, I create new VNETs and delete VNETs very often. Managing static routes in my home router and IP Sec tunnels in each setup has been very cumbersome. Therefore, my curious mind was always looking for a smarter way to do this. If you are in this same boat, join with me. </p><a id="more"></a><p>In summary, BGP peering’s can be established between the Ubiquity USG and the Azure Gateway enabled with BGP. In this blog post, I’m focusing more on the USG configuration and assume that you can setup the rest of the environment by yourself. To explain how this can be setup, I’m going to use my lab as an example. Following is a diagram of my setup. </p><p><img src="diagram.png" alt="Lab Setup Diagram"></p><p>Following are the key properties of the setup that you need to be aware. </p><p><strong>Home Network</strong><br>IP Addressing used in the Home network – 10.1.1.0/24<br>Static Public IP on the USG – 113.76.252.224<br>BGP Peering IP on the USG – 10.1.1.1</p><p><strong>Azure Network – VWAN</strong><br>VPN Gateway Public IP – 21.52.125.78<br>Azure Gateway Peering IP – 10.0.1.14<br>VWAN Hub IP Address space – 10.0.1.0/24<br>VNET IP Address Space – 10.10.0.0/16</p><p>Note that in Azure I have used Azure VWAN for hub and spoke topology. To learn more about Azure VWAN <a href="https://azure.microsoft.com/en-us/services/virtual-wan/" target="_blank" rel="noopener">click here</a>. Azure VWAN Hub can have VPN Gateways. I assume that you have setup the Azure Networking piece beforehand, and I’m not going to be covering that piece in this article. You can refer to <a href="https://docs.microsoft.com/en-us/azure/virtual-wan/virtual-wan-site-to-site-portal" target="_blank" rel="noopener">this</a> article if you need some guidance on the VWAN hub and the VPN gateway setup. By default, it creates two VPN gateway instances. See below screenshot which displays the properties of the two gateways. </p><p><img src="gatewayproperties.png" alt="VWAN Gateway instances"></p><p>In this case I have used only one gateway instance as my home network has only one gateway. </p><p>Now you have all the details required for the VPN to setup. Let’s look at how to configure the USG. Unfortunately, USG configuration can’t be done via the GUI. You will need to use the advance configuration file config.gateway.json. For more details about the advanced configuration file visit this <a href="https://help.ui.com/hc/en-us/articles/215458888-UniFi-USG-Advanced-Configuration-Using-config-gateway-json#:~:text=Introduction-,The%20config.,available%20in%20the%20web%20GUI." target="_blank" rel="noopener">documentation</a>.<br>This file is in the cloud key and the location is explained in the documentation. In my case it is - /srv/unifi/data/sites/<sitename>. If you are editing this for the first time, you will need to create the file. This needs to be a valid JSON file, therefore, be careful and always validate when editing this file.<br>Add the following configuration to the file. Replace you public and local IP in here with your respective IPs. Save the configuration and do a force provision from the Cloud Key. </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;system&quot;: &#123;</span><br><span class="line">        &quot;static-host-mapping&quot;: &#123;</span><br><span class="line">            &quot;host-name&quot;: &#123;</span><br><span class="line">                &quot;test1.snmnest.local&quot;: &#123;</span><br><span class="line">                    &quot;alias&quot;: [</span><br><span class="line">                        &quot;lab&quot;</span><br><span class="line">                    ],</span><br><span class="line">                    &quot;inet&quot;: [</span><br><span class="line">                        &quot;10.1.1.13&quot;</span><br><span class="line">                    ]</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;interfaces&quot;: &#123;</span><br><span class="line">        &quot;vti&quot;: &#123;</span><br><span class="line">            &quot;vti0&quot;: &#123;</span><br><span class="line">                &quot;mtu&quot;: &quot;1436&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;firewall&quot;: &#123;</span><br><span class="line">        &quot;options&quot;: &#123;</span><br><span class="line">            &quot;mss-clamp&quot;: &#123;</span><br><span class="line">                &quot;interface-type&quot;: [</span><br><span class="line">                    &quot;pppoe&quot;,</span><br><span class="line">                    &quot;pptp&quot;,</span><br><span class="line">                    &quot;vti&quot;</span><br><span class="line">                ],</span><br><span class="line">                &quot;mss&quot;: &quot;1350&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;protocols&quot;: &#123;</span><br><span class="line">        &quot;bgp&quot;: &#123;</span><br><span class="line">            &quot;65510&quot;: &#123;</span><br><span class="line">                &quot;neighbor&quot;: &#123;</span><br><span class="line">                    &quot;10.0.1.14&quot;: &#123;</span><br><span class="line">                        &quot;ebgp-multihop&quot;: &quot;4&quot;,</span><br><span class="line">                        &quot;prefix-list&quot;: &#123;</span><br><span class="line">                            &quot;export&quot;: &quot;BGP&quot;,</span><br><span class="line">                            &quot;import&quot;: &quot;BGP&quot;</span><br><span class="line">                        &#125;,</span><br><span class="line">                        &quot;remote-as&quot;: &quot;65515&quot;,</span><br><span class="line">                        &quot;soft-reconfiguration&quot;: &#123;</span><br><span class="line">                            &quot;inbound&quot;: &quot;&#39;&#39;&quot;</span><br><span class="line">                        &#125;,</span><br><span class="line">                        &quot;update-source&quot;: &quot;10.1.1.1&quot;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;network&quot;: &#123;</span><br><span class="line">                    &quot;10.1.1.0&#x2F;24&quot;: &quot;&#39;&#39;&quot;</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;timers&quot;: &#123;</span><br><span class="line">                    &quot;holdtime&quot;: &quot;180&quot;,</span><br><span class="line">                    &quot;keepalive&quot;: &quot;60&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;static&quot;: &#123;</span><br><span class="line">            &quot;interface-route&quot;: &#123;</span><br><span class="line">                &quot;10.0.1.14&#x2F;32&quot;: &#123;</span><br><span class="line">                    &quot;next-hop-interface&quot;: &#123;</span><br><span class="line">                        &quot;vti0&quot;: &quot;&#39;&#39;&quot;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;policy&quot;: &#123;</span><br><span class="line">        &quot;prefix-list&quot;: &#123;</span><br><span class="line">            &quot;BGP&quot;: &#123;</span><br><span class="line">                &quot;rule&quot;: &#123;</span><br><span class="line">                    &quot;10&quot;: &#123;</span><br><span class="line">                        &quot;action&quot;: &quot;deny&quot;,</span><br><span class="line">                        &quot;description&quot;: &quot;deny-localgw&quot;,</span><br><span class="line">                        &quot;prefix&quot;: &quot;113.76.252.224&#x2F;32&quot;</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;100&quot;: &#123;</span><br><span class="line">                        &quot;action&quot;: &quot;permit&quot;,</span><br><span class="line">                        &quot;description&quot;: &quot;permit-localsubnet&quot;,</span><br><span class="line">                        &quot;prefix&quot;: &quot;10.1.1.0&#x2F;24&quot;</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;110&quot;: &#123;</span><br><span class="line">                        &quot;action&quot;: &quot;permit&quot;,</span><br><span class="line">                        &quot;description&quot;: &quot;permit-remotesubnet&quot;,</span><br><span class="line">                        &quot;ge&quot;: &quot;16&quot;,</span><br><span class="line">                        &quot;prefix&quot;: &quot;10.0.0.0&#x2F;8&quot;</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;20&quot;: &#123;</span><br><span class="line">                        &quot;action&quot;: &quot;deny&quot;,</span><br><span class="line">                        &quot;description&quot;: &quot;deny-remotegw&quot;,</span><br><span class="line">                        &quot;prefix&quot;: &quot;21.52.125.78&#x2F;32&quot;</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;30&quot;: &#123;</span><br><span class="line">                        &quot;action&quot;: &quot;deny&quot;,</span><br><span class="line">                        &quot;description&quot;: &quot;deny-localpeer&quot;,</span><br><span class="line">                        &quot;prefix&quot;: &quot;10.1.1.1&#x2F;32&quot;</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;40&quot;: &#123;</span><br><span class="line">                        &quot;action&quot;: &quot;deny&quot;,</span><br><span class="line">                        &quot;description&quot;: &quot;deny-remotepeer&quot;,</span><br><span class="line">                        &quot;prefix&quot;: &quot;10.0.1.14&#x2F;32&quot;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;vpn&quot;: &#123;</span><br><span class="line">        &quot;ipsec&quot;: &#123;</span><br><span class="line">            &quot;auto-firewall-nat-exclude&quot;: &quot;enable&quot;,</span><br><span class="line">            &quot;esp-group&quot;: &#123;</span><br><span class="line">                &quot;VWAN01&quot;: &#123;</span><br><span class="line">                    &quot;compression&quot;: &quot;disable&quot;,</span><br><span class="line">                    &quot;lifetime&quot;: &quot;27000&quot;,</span><br><span class="line">                    &quot;mode&quot;: &quot;tunnel&quot;,</span><br><span class="line">                    &quot;pfs&quot;: &quot;disable&quot;,</span><br><span class="line">                    &quot;proposal&quot;: &#123;</span><br><span class="line">                        &quot;1&quot;: &#123;</span><br><span class="line">                            &quot;encryption&quot;: &quot;aes256&quot;,</span><br><span class="line">                            &quot;hash&quot;: &quot;sha1&quot;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;ike-group&quot;: &#123;</span><br><span class="line">                &quot;VWAN01&quot;: &#123;</span><br><span class="line">                    &quot;ikev2-reauth&quot;: &quot;no&quot;,</span><br><span class="line">                    &quot;key-exchange&quot;: &quot;ikev2&quot;,</span><br><span class="line">                    &quot;lifetime&quot;: &quot;28800&quot;,</span><br><span class="line">                    &quot;proposal&quot;: &#123;</span><br><span class="line">                        &quot;1&quot;: &#123;</span><br><span class="line">                            &quot;dh-group&quot;: &quot;2&quot;,</span><br><span class="line">                            &quot;encryption&quot;: &quot;aes256&quot;,</span><br><span class="line">                            &quot;hash&quot;: &quot;sha1&quot;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;site-to-site&quot;: &#123;</span><br><span class="line">                &quot;peer&quot;: &#123;</span><br><span class="line">                    &quot;21.52.125.78&quot;: &#123;</span><br><span class="line">                        &quot;authentication&quot;: &#123;</span><br><span class="line">                            &quot;mode&quot;: &quot;pre-shared-secret&quot;,</span><br><span class="line">                            &quot;pre-shared-secret&quot;: &quot;mykeyhereplease&quot;</span><br><span class="line">                        &#125;,</span><br><span class="line">                        &quot;connection-type&quot;: &quot;respond&quot;,</span><br><span class="line">                        &quot;description&quot;: &quot;ipsec&quot;,</span><br><span class="line">                        &quot;ike-group&quot;: &quot;VWAN01&quot;,</span><br><span class="line">                        &quot;ikev2-reauth&quot;: &quot;inherit&quot;,</span><br><span class="line">                        &quot;local-address&quot;: &quot;113.76.252.224&quot;,</span><br><span class="line">                        &quot;vti&quot;: &#123;</span><br><span class="line">                            &quot;bind&quot;: &quot;vti0&quot;,</span><br><span class="line">                            &quot;esp-group&quot;: &quot;VWAN01&quot;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="provision.png" alt="Provision Button"></p><p>Once the configuration is pushed. Restart the USG. </p><p>Once it’s successfully restarted, ssh into the USG. Then check the BGP status using the following commands. It should show the results as below. </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show ip bgp summary</span><br></pre></td></tr></table></figure><p><img src="command1.png" alt="Command1"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show ip bgp neighbor</span><br></pre></td></tr></table></figure><p><img src="command2.png" alt="Command2"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show ip bgp neighbors 10.0.1.14 advertised-routes</span><br></pre></td></tr></table></figure><p>This command shows the routes advertised to the remote peer<br><img src="command3.png" alt="Command3"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show ip bgp neighbors 10.0.1.14 received-routes</span><br></pre></td></tr></table></figure><p>This command shows the routes recieved from the remote peer<br><img src="command4.png" alt="Command4"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show ip bgp</span><br></pre></td></tr></table></figure><p><img src="command5.png" alt="Command5"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show ip route</span><br></pre></td></tr></table></figure><p><img src="command6.png" alt="Command6"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;In this blog post, I’m going to be sharing my knowledge that I gathered during a lab setup. Last weekend, I was playing with Ubiquiti USG BGP features and was wondering If I could establish BGP peering with my Azure VPN Gateway. This way, it could dynamically exchange routes between my home network and Azure. I typically have a hybrid networking configured between my home network and Azure. My Azure network is very dynamic, I create new VNETs and delete VNETs very often. Managing static routes in my home router and IP Sec tunnels in each setup has been very cumbersome. Therefore, my curious mind was always looking for a smarter way to do this. If you are in this same boat, join with me. &lt;/p&gt;
    
    </summary>
    
    
      <category term="Networking" scheme="https://sameeraman.github.io/categories/networking/"/>
    
    
      <category term="Networking" scheme="https://sameeraman.github.io/tags/networking/"/>
    
      <category term="VWAN" scheme="https://sameeraman.github.io/tags/vwan/"/>
    
      <category term="Ubiquiti" scheme="https://sameeraman.github.io/tags/ubiquiti/"/>
    
  </entry>
  
  <entry>
    <title>Web App Private Endpoints vs Service Endpoints vs App Service Environments</title>
    <link href="https://sameeraman.github.io/2020/07/09/internalwebapphostingoptions/"/>
    <id>https://sameeraman.github.io/2020/07/09/internalwebapphostingoptions/</id>
    <published>2020-07-09T10:34:48.000Z</published>
    <updated>2025-06-02T14:18:02.376Z</updated>
    
    <content type="html"><![CDATA[<p>Recently, I got an opportunity to compare the Private Endpoint for Web Apps, Service Endpoints for Web Apps and App Service Environments. I thought it would be good to write a blog post on the observations and the comparison I learned. Limiting the attack vector for the web applications and exposing the application only to the customer private networks is a very common requirement when you talk to customers. Therefore, this blog is about a comparison between the most commonly used hosting methods for <strong>internal-facing</strong> web applications in Azure. </p><a id="more"></a><h2 id="Private-Endpoints-for-Web-Apps"><a href="#Private-Endpoints-for-Web-Apps" class="headerlink" title="Private Endpoints for Web Apps"></a>Private Endpoints for Web Apps</h2><p>With the announcement of the <a href="https://docs.microsoft.com/en-us/azure/app-service/networking/private-endpoint" target="_blank" rel="noopener">Private Endpoints for Web Apps</a>, it opens up a new architecture for making Azure Web Apps available to the Azure Networks. This method creates a Private IP address in your virtual network dedicated for the Web App instance you choose. This private IP can be used as a secure entry point for the Web Application. This feature combined with external access blocked to the web app makes the application available only to the local network. </p><p>The traffic originating from an end-user traverse the virtual network to the private endpoint for the web app. Then it goes through the Microsoft Backbone to the Web App. It never goes to the Public Internet. Hence, this is a much secure way to have connectivity to internal-facing web applications. </p><p><img src="/blog/2020/07/09/internalwebapphostingoptions/PrivateEndpoints.png" alt="Private Endpoint for Web Apps"></p><p>The above diagram shows the high-level architecture for the private endpoint for web apps. One of the key features of this architecture is that this model works with the hybrid networking configuration as well. This means, your on-premises users can route to your web application using the private endpoint in the virtual network. This also provides additional security features. Private endpoint makes sure that only the allowed web application instance can be accessed by the private endpoint. It can not access any other service through it. Therefore, it protects you from any possible data exfiltration from your network. </p><p>Note that this feature is still in public preview as of 10/07/2020.</p><h2 id="Service-Endpoints-for-Web-Apps"><a href="#Service-Endpoints-for-Web-Apps" class="headerlink" title="Service Endpoints for Web Apps"></a>Service Endpoints for Web Apps</h2><p><a href="https://docs.microsoft.com/en-us/azure/virtual-network/virtual-network-service-endpoints-overview" target="_blank" rel="noopener">Service Endpoints</a> for Web Apps provide secure connectivity to Azure Web apps over an optmized route over the Microsoft backbone. When compared with the Private Endpoints, Service Endpoints does not provide a private IP in your network. Instead, it will add special routes to your VNet, so that the Web App traffic will route via the Microsoft backbone to the web app. Therefore, it will not leave the Microsoft network when reaching the web app. You can also combine Service Endpoints and restrict public access to only allow traffic from the virtual networks selected. </p><p><img src="/blog/2020/07/09/internalwebapphostingoptions/ServiceEndpoints.png" alt="Service Endpoint for Web Apps"></p><p>The diagram above shows the high level architecture for the Service Endpoints for web apps. One of the key functional differences in service endpoint, when compared to private endpoints, is that this provides private access to the full service in the Azure Region whereas in Private link it is only to that instance. </p><p>Service endpoints are simple to configure and easier option when compared to the other two.</p><h2 id="App-Service-Environments"><a href="#App-Service-Environments" class="headerlink" title="App Service Environments"></a>App Service Environments</h2><p>Azure <a href="https://docs.microsoft.com/en-us/azure/app-service/environment/intro" target="_blank" rel="noopener">App Service environments</a> provide a fully isolated and dedicated environment in a customer network to run web apps. This provisions a dedicated instance of the app hosting plan in your network as opposed to the multi-tenanted offerings in the other two option. This allows customers to fully control network traffic that goes in and out of the web app. </p><p><img src="/blog/2020/07/09/internalwebapphostingoptions/ASE.png" alt="App Service Environments"></p><p>The above high-level architecture diagram shows how the App service environment sits in the network. Providing internal access to the application is easy since it sits within the virtual network. If you have hybrid connectivity via an ExpressRoute or a Site-to-Site VPN, then it can route to the web application without any special configuration. </p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>In this post, we looked at different architecture options for hosting a Web App which is exposed to the internal network only. See the below table, as a summary of features, functionalities and complexities discussed above. </p><table><thead><tr><th>Private Endpoints</th><th>Service Endpoints</th><th>App Service Environments</th></tr></thead><tbody><tr><td>Provide Access to Web Apps over Private IP Address</td><td>Provide Access to Web Apps over optimized backbone routing</td><td>Web Apps are provisioned within the customer network</td></tr><tr><td>Access is restricted per Web App Instance</td><td>Access is restricted per Web app Service</td><td>Access restriction up to the customer as the service is in the customer network</td></tr><tr><td>Complexity: Planning and initial configuration required</td><td>Complexity: Easy to setup</td><td>Complexity: Planning and Initial configuration required</td></tr><tr><td>In-built data exfiltration protection</td><td>Traffic will need to be passed through an NVA/Firewall for exfiltration protection</td><td>N/A as the application is entirely in the customer network</td></tr><tr><td>Cost compared to the other two options: moderate</td><td>Cost compared to the other two options: Can be low and depends on the application</td><td>Cost compared to the other two options: Higher running cost</td></tr><tr><td>Multi-tenant Hosting plan</td><td>Multi-tenant Hosting plan</td><td>Dedicated hosting plan</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Recently, I got an opportunity to compare the Private Endpoint for Web Apps, Service Endpoints for Web Apps and App Service Environments. I thought it would be good to write a blog post on the observations and the comparison I learned. Limiting the attack vector for the web applications and exposing the application only to the customer private networks is a very common requirement when you talk to customers. Therefore, this blog is about a comparison between the most commonly used hosting methods for &lt;strong&gt;internal-facing&lt;/strong&gt; web applications in Azure. &lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Networking" scheme="https://sameeraman.github.io/tags/networking/"/>
    
      <category term="Apps" scheme="https://sameeraman.github.io/tags/apps/"/>
    
  </entry>
  
  <entry>
    <title>Docker Cheat Sheet</title>
    <link href="https://sameeraman.github.io/2020/07/04/dockercheatsheet/"/>
    <id>https://sameeraman.github.io/2020/07/04/dockercheatsheet/</id>
    <published>2020-07-04T09:34:48.000Z</published>
    <updated>2025-06-02T14:18:02.373Z</updated>
    
    <content type="html"><![CDATA[<p>I recently went through my second study phase around docker containers recently. Docker is a huge topic these days and widly used in the application containerization. I use Docker at home and at work in many projects. I thought it would be useful to create a Docker Cheat Sheet for my reference and share that among the community and that lead to this post. In this post, I’m going to list the most common commands used when playing with Docker containers. </p><a id="more"></a><h2 id="General-Listing-Commands"><a href="#General-Listing-Commands" class="headerlink" title="General Listing Commands"></a>General Listing Commands</h2><ul><li><p>List all docker containers</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker ps -a</span><br></pre></td></tr></table></figure></li><li><p>List running docker containers</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker ps -a</span><br></pre></td></tr></table></figure></li><li><p>List docker images in the local store</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker images</span><br></pre></td></tr></table></figure></li><li><p>Download and store an image from the internet</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull ubuntu</span><br></pre></td></tr></table></figure></li></ul><h2 id="Running-Docker-Containers"><a href="#Running-Docker-Containers" class="headerlink" title="Running Docker Containers"></a>Running Docker Containers</h2><ul><li><p>Run an instance of a container image</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run ubuntu</span><br></pre></td></tr></table></figure></li><li><p>Run an instance of a container image in detached mode (run in background)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d nginx</span><br></pre></td></tr></table></figure></li><li><p>Run an instance of a Ubuntu container images with terminal and input attached. </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -it ubuntu bash</span><br></pre></td></tr></table></figure></li></ul><h2 id="Stopping-and-Removing-Docker-Containers"><a href="#Stopping-and-Removing-Docker-Containers" class="headerlink" title="Stopping and Removing Docker Containers"></a>Stopping and Removing Docker Containers</h2><ul><li><p>Stop a running container instance</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker stop ubuntu</span><br></pre></td></tr></table></figure></li><li><p>Remove a terminated container (Container Id = b5a12307c030)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker rm b5a12307c030</span><br></pre></td></tr></table></figure></li><li><p>Remove a container image from the local store</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker rmi ubuntu</span><br></pre></td></tr></table></figure></li></ul><h2 id="Container-interaction"><a href="#Container-interaction" class="headerlink" title="Container interaction"></a>Container interaction</h2><ul><li><p>Run a container instance interactively</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker  run -it ubuntu bash</span><br></pre></td></tr></table></figure></li><li><p>Remote into a running container instance (Container id = b5a12307c030 )</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it b5a12307c030 bash</span><br></pre></td></tr></table></figure></li><li><p>Execute a command in a running container Eg: ps -eaf</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec b5a12307c030 ps -eaf</span><br></pre></td></tr></table></figure></li></ul><h2 id="Map-a-Port-to-a-Container"><a href="#Map-a-Port-to-a-Container" class="headerlink" title="Map a Port to a Container"></a>Map a Port to a Container</h2><ul><li>Map a host port to a new container instance (Host Port = 5000, Container Port = 80, Container image = nginx)<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -p 80:5000 nginx -d</span><br></pre></td></tr></table></figure></li></ul><h2 id="Mount-a-Volume"><a href="#Mount-a-Volume" class="headerlink" title="Mount a Volume"></a>Mount a Volume</h2><ul><li>Mount a host volume to a new container (Host Volume Path = /opt/mydata, Container Mount Path = /var/lib/mysql)<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -v &#x2F;opt&#x2F;mydata:&#x2F;var&#x2F;lib&#x2F;mysql mysql</span><br></pre></td></tr></table></figure></li></ul><h2 id="Inspect-Container-Logs"><a href="#Inspect-Container-Logs" class="headerlink" title="Inspect Container Logs"></a>Inspect Container Logs</h2><ul><li>Inspect container logs of Container ID = b5a12307c030<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker logs b5a12307c030</span><br></pre></td></tr></table></figure></li></ul><h2 id="Other-Handy-Commands"><a href="#Other-Handy-Commands" class="headerlink" title="Other Handy Commands"></a>Other Handy Commands</h2><ul><li><p>Remove all excited Containers</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker rm -f $(docker ps -q --filter &quot;status&#x3D;exited&quot;)</span><br></pre></td></tr></table></figure></li><li><p>Monitor Docker disk consumption</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker system df</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I recently went through my second study phase around docker containers recently. Docker is a huge topic these days and widly used in the application containerization. I use Docker at home and at work in many projects. I thought it would be useful to create a Docker Cheat Sheet for my reference and share that among the community and that lead to this post. In this post, I’m going to list the most common commands used when playing with Docker containers. &lt;/p&gt;
    
    </summary>
    
    
      <category term="Containers" scheme="https://sameeraman.github.io/categories/containers/"/>
    
    
      <category term="Containers" scheme="https://sameeraman.github.io/tags/containers/"/>
    
      <category term="Docker" scheme="https://sameeraman.github.io/tags/docker/"/>
    
  </entry>
  
</feed>
